#!/usr/bin/env python3

import argparse
import json
import os
import shutil
import subprocess
import sys
import tempfile
from collections import deque
from datetime import datetime, timezone
from pathlib import Path
from typing import IO, Any, Deque, Dict, Iterable, List, Optional, Tuple

import requests
from colored import attr, fg
from github import Auth, Github, UnknownObjectException
from yaspin import yaspin

PkgConfig = Dict[str, Any]
LockData = Dict[str, Any]

DIM: str = attr("dim")
GREEN: str = fg("green")
CYAN: str = fg("cyan")
YELLOW: str = fg("yellow")
RED: str = fg("red")
BOLD: str = attr("bold")
RESET: str = attr("reset")

PKG_JSON: Path = Path.home() / "pkg.json"
PKG_LOCK: Path = Path.home() / "pkg.lock"
DEFAULT_INSTALL_DIR: Path = Path.home() / ".local" / "bin"
BUILD_LOG: Path = Path("/tmp/pack.build.log")

BUILD_LOG_LINES: int = 15
HTTP_TIMEOUT: int = 30


class PackageError(Exception):
    """Raised when a package operation fails in a recoverable way."""


def get_auth_token(g: Github) -> Optional[str]:
    """Extract the raw token string from a Github client, if authenticated."""
    auth = getattr(g, "auth", None)
    if auth and hasattr(auth, "token"):
        return auth.token  # type: ignore[union-attr]
    return None


def get_github_client() -> Github:
    """Create an authenticated GitHub client.

    Tries GITHUB_TOKEN env var, then gh CLI, then falls back to unauthenticated.
    """
    token: Optional[str] = os.environ.get("GITHUB_TOKEN")
    if token:
        return Github(auth=Auth.Token(token))

    try:
        result: subprocess.CompletedProcess[str] = subprocess.run(
            ["gh", "auth", "token"],
            capture_output=True,
            text=True,
        )
        if result.returncode == 0 and result.stdout.strip():
            return Github(auth=Auth.Token(result.stdout.strip()))
    except FileNotFoundError:
        pass

    return Github()


def validate_config(config: PkgConfig) -> None:
    """Validate the structure of pkg.json and exit on errors."""
    packages = config.get("packages")
    if packages is None:
        print(f"  {RED}[F]{RESET} pkg.json: missing 'packages' key", file=sys.stderr)
        sys.exit(1)
    if not isinstance(packages, dict):
        print(
            f"  {RED}[F]{RESET} pkg.json: 'packages' must be an object",
            file=sys.stderr,
        )
        sys.exit(1)
    for name, pkg in packages.items():
        if "repo" not in pkg:
            print(
                f"  {RED}[F]{RESET} pkg.json: '{name}' missing required 'repo' key",
                file=sys.stderr,
            )
            sys.exit(1)
        for req in pkg.get("requires", []):
            if req not in packages:
                print(
                    f"  {RED}[F]{RESET} pkg.json: '{name}' requires"
                    f" unknown package '{req}'",
                    file=sys.stderr,
                )
                sys.exit(1)


def load_pkg_json() -> PkgConfig:
    if not PKG_JSON.exists():
        print(f"  {RED}[F]{RESET} {PKG_JSON} not found", file=sys.stderr)
        sys.exit(1)
    with open(PKG_JSON) as f:
        config: PkgConfig = json.load(f)
    validate_config(config)
    return config


def load_pkg_lock() -> LockData:
    if PKG_LOCK.exists():
        with open(PKG_LOCK) as f:
            return json.load(f)
    return {"packages": {}}


def save_pkg_lock(lock: LockData) -> None:
    with open(PKG_LOCK, "w") as f:
        json.dump(lock, f, indent=2)
        f.write("\n")


def topo_sort(targets: List[str], packages: Dict[str, "PkgConfig"]) -> List[str]:
    """Return *targets* ordered so that dependencies come before dependents.

    Only packages that appear in *targets* are included.  If a required
    package is not in the target list but exists in *packages*, it is
    pulled in automatically so it can be installed first.
    """
    target_set: set[str] = set(targets)

    # Expand: if a target requires X and X is in packages, add X
    queue: Deque[str] = deque(targets)
    while queue:
        name = queue.popleft()
        for req in packages.get(name, {}).get("requires", []):
            if req not in target_set and req in packages:
                target_set.add(req)
                queue.append(req)

    in_degree: Dict[str, int] = {n: 0 for n in target_set}
    dependents: Dict[str, List[str]] = {n: [] for n in target_set}

    for name in target_set:
        for req in packages.get(name, {}).get("requires", []):
            if req in target_set:
                in_degree[name] += 1
                dependents[req].append(name)

    ready: Deque[str] = deque(n for n in targets if in_degree.get(n, 0) == 0)
    # Also add any pulled-in deps that aren't already queued
    for n in target_set - set(targets):
        if in_degree[n] == 0:
            ready.append(n)

    ordered: List[str] = []
    while ready:
        node = ready.popleft()
        ordered.append(node)
        for dep in dependents[node]:
            in_degree[dep] -= 1
            if in_degree[dep] == 0:
                ready.append(dep)

    if len(ordered) != len(target_set):
        cycle = target_set - set(ordered)
        raise RuntimeError(
            f"dependency cycle detected among: {', '.join(sorted(cycle))}"
        )

    return ordered


class TagShim:
    """Minimal release-like wrapper around a Git tag."""

    def __init__(self, tag: Any) -> None:
        self.tag_name: str = tag.name
        self.tarball_url: str = tag.tarball_url

    @staticmethod
    def get_assets() -> List[Any]:
        return []


def get_latest_release(repo: Any) -> Any:
    """Return the latest release, falling back to the most recent by date.

    Some repos (e.g. rustup) don't mark any release as 'latest', causing the
    /releases/latest endpoint to 404.  In that case, fetch all releases and
    return the most recent non-draft, non-prerelease one.  If there are no
    releases at all, fall back to the latest tag.
    """
    try:
        return repo.get_latest_release()
    except UnknownObjectException:
        for release in repo.get_releases():
            if not release.draft and not release.prerelease:
                return release

    tags = repo.get_tags()
    if tags.totalCount:
        return TagShim(tags[0])

    raise RuntimeError(f"no suitable release or tag found for {repo.full_name}")


def find_asset(assets: Iterable[Any], artifact: Optional[str]) -> Optional[Any]:
    for asset in assets:
        if artifact:
            if asset.name == artifact:
                return asset
        elif asset.name.lower().endswith(".appimage"):
            return asset
    return None


def download_to(resp: requests.Response, dest: Path) -> None:
    with open(dest, "wb") as f:
        for chunk in resp.iter_content(chunk_size=8192):
            f.write(chunk)


def resolve_artifact(
    latest: Any, artifact: Optional[str], name: str, version: str
) -> Tuple[str, str]:
    """Resolve the download URL and artifact filename from a release.

    Returns (download_url, artifact_name).  Raises PackageError if no
    matching asset is found.
    """
    if artifact == "source":
        return latest.tarball_url, f"{name}-{version}.tar.gz"

    resolved: Optional[str] = artifact.format(version=version) if artifact else None
    asset = find_asset(latest.get_assets(), resolved)
    if not asset:
        kind: str = f"artifact '{resolved}'" if resolved else "appimage"
        raise PackageError(f"no {kind} found in release assets")
    return asset.browser_download_url, asset.name


def download_with_spinner(
    url: str, dest: Path, label: str, auth_token: Optional[str] = None
) -> None:
    """Download a file with a spinner, optional auth, and timeout."""
    headers: Dict[str, str] = {}
    if auth_token:
        headers["Authorization"] = f"token {auth_token}"
    with yaspin(text=f"downloading {label}...", color="cyan"):
        resp: requests.Response = requests.get(
            url, stream=True, headers=headers, timeout=HTTP_TIMEOUT
        )
        resp.raise_for_status()
        download_to(resp, dest)
    print(f"  {GREEN}[OK]{RESET} downloaded {label}")


def clear_lines(n: int) -> None:
    """Move cursor up n lines and clear everything below."""
    if n > 0:
        sys.stdout.write(f"\033[{n}A\033[J")
        sys.stdout.flush()


def run_build_cmds(
    cmds: List[str], variables: Dict[str, str], cwd: str, log: IO[str]
) -> None:
    term_cols: int = shutil.get_terminal_size((80, 24)).columns
    max_line_len: int = term_cols - 6

    for i, cmd in enumerate(cmds, 1):
        expanded: str = cmd.format(**variables)
        print(f"  {BOLD}[{i}/{len(cmds)}]{RESET} {expanded}")
        log.write(f"$ {expanded}\n")

        proc: subprocess.Popen[str] = subprocess.Popen(
            expanded,
            shell=True,
            cwd=cwd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
        )
        assert proc.stdout is not None

        buf: Deque[str] = deque(maxlen=BUILD_LOG_LINES)
        lines_on_screen: int = 0

        try:
            for line in proc.stdout:
                raw: str = line.rstrip("\n")
                buf.append(raw)
                log.write(line)

                clear_lines(lines_on_screen)

                lines_on_screen = len(buf)
                for buf_line in buf:
                    display: str = buf_line[:max_line_len]
                    sys.stdout.write(f"  {DIM}    {display}{RESET}\n")
                sys.stdout.flush()
        except BaseException:
            proc.terminate()
            proc.wait()
            clear_lines(lines_on_screen)
            raise

        returncode: int = proc.wait()
        log.write(f"exit {returncode}\n\n")
        log.flush()

        clear_lines(lines_on_screen)

        if returncode != 0:
            for buf_line in buf:
                print(f"  {DIM}    {buf_line}{RESET}")
            print(f"  {DIM}full log: {BUILD_LOG}{RESET}")
            raise RuntimeError(f"build command failed (exit {returncode}): {expanded}")


def update_package(
    name: str,
    pkg_config: PkgConfig,
    lock: LockData,
    g: Github,
    install_dir: Path,
    log: IO[str],
    force: bool = False,
    yes: bool = False,
) -> None:
    repo_name: str = pkg_config["repo"]
    artifact: Optional[str] = pkg_config.get("artifact")
    bin_name: str = pkg_config.get("bin", name)
    auth_token: Optional[str] = get_auth_token(g)

    print(f"\n{BOLD}{CYAN}── {name} {RESET}{DIM}({repo_name}){RESET}")

    requires: List[str] = pkg_config.get("requires", [])
    if requires:
        missing: List[str] = [r for r in requires if r not in lock["packages"]]
        if missing:
            raise PackageError(f"missing required packages: {', '.join(missing)}")

    current: Dict[str, Any] = lock["packages"].get(name, {})
    current_version: str = current.get("version", "none")
    print(f"  {DIM}installed{RESET}  {current_version}")

    repo = g.get_repo(repo_name)
    latest = get_latest_release(repo)
    latest_version: str = latest.tag_name.removeprefix("v")
    print(f"  {DIM}latest{RESET}     {latest_version}")

    if current_version == latest_version and not force:
        print(f"  {GREEN}[OK]{RESET} already up to date")
        return

    download_url, artifact_name = resolve_artifact(
        latest, artifact, name, latest_version
    )

    print(f"  {DIM}artifact{RESET}   {artifact_name}")
    if not yes:
        answer: str = input(
            f"  {YELLOW}update {name} from {current_version}"
            f" to {latest_version}? [y/N]{RESET} "
        )
        if answer.lower() != "y":
            print(f"  {YELLOW}[SKIP]{RESET} skipped")
            return

    pre_cmds: Optional[List[str]] = pkg_config.get("pre")
    build_cmds: Optional[List[str]] = pkg_config.get("cmds")

    install_dir.mkdir(parents=True, exist_ok=True)

    if pre_cmds:
        pre_vars: Dict[str, str] = {
            "install_dir": str(install_dir),
            "bin": bin_name,
            "version": latest_version,
        }
        print(f"  {DIM}running pre commands...{RESET}")
        log.write(f"=== {name} pre ===\n")
        with tempfile.TemporaryDirectory(prefix=f"pack_{name}_pre_") as pre_tmpdir:
            run_build_cmds(pre_cmds, pre_vars, cwd=pre_tmpdir, log=log)

    if build_cmds:
        with tempfile.TemporaryDirectory(prefix=f"pack_{name}_") as tmpdir:
            artifact_path: Path = Path(tmpdir) / artifact_name
            download_with_spinner(
                download_url, artifact_path, artifact_name, auth_token
            )

            variables: Dict[str, str] = {
                "artifact": str(artifact_path),
                "install_dir": str(install_dir),
                "bin": bin_name,
                "version": latest_version,
                "tmpdir": tmpdir,
            }

            log.write(f"=== {name} ({repo_name}) ===\n")
            run_build_cmds(build_cmds, variables, cwd=tmpdir, log=log)
    else:
        target: Path = install_dir / bin_name
        backup: Path = target.with_suffix(".backup")

        if target.exists():
            target.rename(backup)

        try:
            download_with_spinner(download_url, target, artifact_name, auth_token)
            target.chmod(0o755)
        except Exception:
            if backup.exists():
                backup.rename(target)
            raise

        if backup.exists():
            backup.unlink()

    lock["packages"][name] = {
        "version": latest_version,
        "artifact": artifact_name,
        "repo": repo_name,
        "installed_at": datetime.now(timezone.utc).isoformat(),
        "url": download_url,
    }

    print(f"  {GREEN}[OK]{RESET} installed {name} v{latest_version}")


def cmd_update(args: argparse.Namespace, config: PkgConfig) -> None:
    lock: LockData = load_pkg_lock()
    install_dir: Path = Path(
        config.get("install_dir", str(DEFAULT_INSTALL_DIR))
    ).expanduser()
    packages: Dict[str, PkgConfig] = config.get("packages", {})

    g: Github = get_github_client()
    targets: List[str] = args.packages if args.packages else list(packages.keys())
    force_targets: set[str] = (
        (set(args.packages) if args.packages else set(packages.keys()))
        if args.force
        else set()
    )
    targets = topo_sort(targets, packages)

    with open(BUILD_LOG, "w") as log:
        for name in targets:
            if name not in packages:
                print(f"  {RED}[F]{RESET} unknown package: {name}", file=sys.stderr)
                continue
            try:
                update_package(
                    name,
                    packages[name],
                    lock,
                    g,
                    install_dir,
                    log=log,
                    force=name in force_targets,
                    yes=args.yes,
                )
            except Exception as e:
                print(f"  {RED}[F]{RESET} {e}", file=sys.stderr)

    save_pkg_lock(lock)


def cmd_list(config: PkgConfig) -> None:
    lock: LockData = load_pkg_lock()
    packages: Dict[str, PkgConfig] = config.get("packages", {})
    lock_pkgs: Dict[str, Any] = lock["packages"]

    for name in packages:
        if name in lock_pkgs:
            info: Dict[str, Any] = lock_pkgs[name]
            ts: str = info.get("installed_at", "unknown")
            print(
                f"  {CYAN}{name}{RESET}: {GREEN}v{info['version']}{RESET}"
                f" {DIM}(installed {ts}){RESET}"
            )
        else:
            print(f"  {CYAN}{name}{RESET}: {DIM}not installed{RESET}")


def cmd_status(config: PkgConfig) -> None:
    lock: LockData = load_pkg_lock()
    packages: Dict[str, PkgConfig] = config.get("packages", {})
    lock_pkgs: Dict[str, Any] = lock["packages"]

    g: Github = get_github_client()

    StatusResult = Tuple[str, str, Optional[str], Optional[Exception]]
    results: List[StatusResult] = []

    with yaspin(text="checking for updates...", color="cyan"):
        for name, pkg_config in packages.items():
            current_version: str = lock_pkgs.get(name, {}).get("version", "none")
            try:
                repo = g.get_repo(pkg_config["repo"])
                latest = get_latest_release(repo)
                latest_version: str = latest.tag_name.removeprefix("v")
                results.append((name, current_version, latest_version, None))
            except Exception as e:
                results.append((name, current_version, None, e))

    for name, current, latest, err in results:
        if err:
            print(f"  {RED}[F]{RESET} {name}: {current} {DIM}(error: {err}){RESET}")
        elif current != latest:
            print(
                f"  {YELLOW}[NEW]{RESET} {BOLD}{name}{RESET}:"
                f" {current} {YELLOW}->{RESET} {latest}"
            )
        else:
            print(f"  {GREEN}[OK]{RESET} {name}: {GREEN}{current}{RESET}")


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Update packages from GitHub releases",
        epilog="""\
package config (~/pkg.json):
  each entry under "packages" supports:
    repo          GitHub owner/repo (required)
    artifact      release asset to download:
                    - omit to auto-detect first .appimage
                    - exact name, e.g. "nvim-linux-x86_64.appimage"
                    - supports {version} templating, e.g. "tmux-{version}.tar.gz"
                    - "source" to download the release source tarball
    bin           name for the installed binary (defaults to package name)
    requires      array of package names (from pkg.json) that must be installed
                  before this package; missing deps cause the package to be skipped
    pre           array of shell commands to run before download/build
                  available variables: {install_dir} {bin} {version}
    cmds          array of shell commands to run after downloading to /tmp
                  available variables: {artifact} {install_dir} {bin} {version} {tmpdir}

examples:
  pack                      update all packages
  pack update nvim tmux     update specific packages
  pack update -f nvim       force re-download even if up to date
  pack update -y            update all without prompts
  pack status               check which packages have updates available
  pack list                 show installed versions from the lockfile""",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    sub = parser.add_subparsers(dest="command")

    p_update = sub.add_parser("update", help="download and install latest releases")
    p_update.add_argument(
        "packages", nargs="*", help="packages to update (default: all)"
    )
    p_update.add_argument(
        "-f",
        "--force",
        action="store_true",
        help="re-download even if already up to date",
    )
    p_update.add_argument(
        "-y",
        "--yes",
        action="store_true",
        help="skip confirmation prompts",
    )

    sub.add_parser("list", help="show installed packages and versions from ~/pkg.lock")
    sub.add_parser("status", help="check for available updates without installing")

    args: argparse.Namespace = parser.parse_args()
    config: PkgConfig = load_pkg_json()

    if args.command == "update" or args.command is None:
        if args.command is None:
            args.packages = []
            args.force = False
            args.yes = False
        cmd_update(args, config)
    elif args.command == "list":
        cmd_list(config)
    elif args.command == "status":
        cmd_status(config)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print(f"\n{DIM}aborted{RESET}")
        sys.exit(130)
    except Exception as e:
        print(f"{RED}[F]{RESET} {e}", file=sys.stderr)
        sys.exit(1)
